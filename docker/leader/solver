#!/usr/bin/env python3
import json
import logging
import os
import subprocess
import sys

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')


class Runner:
    def __init__(self, request_directory: str):
        self.logger = logging.getLogger("Runner")
        self.logger.setLevel(logging.INFO)
        self.request_directory = request_directory

    def run(self, cmd: list):
        self.logger.info("Running command: %s", str(cmd))
        
        stdout_target_loc = os.path.join(self.request_directory, "stdout.log")
        stderr_target_loc = os.path.join(self.request_directory, "stderr.log")
        
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        with open(os.path.join(self.request_directory, stdout_target_loc), "w") as stdout_handle:
            for line in proc.stdout:
                line_str = line.decode("UTF-8")
                self.logger.info(f"STDOUT: {line_str}")
                stdout_handle.write(line_str)
        #with open(os.path.join(self.request_directory, stderr_target_loc), "w") as stderr_handle:
        #    for line in proc.stderr:
        #        line_str = line.decode("UTF-8")
        #        self.logger.info(f"STDERR: {line_str}")
        #        stderr_handle.write(line_str)

        return_code = proc.returncode
       
        return {
            "stdout": stdout_target_loc,
            "stderr": stderr_target_loc,
            "return_code": return_code,
            "output_directory": self.request_directory
        }

    def get_input_json(self):
        input = os.path.join(self.request_directory, "input.json")
        with open(input) as f:
            return json.loads(f.read())
    
    def create_hostfile(self,ips, request_dir):
        hostfile_path = os.path.join(request_dir, 'combined_hostfile')
        with open(hostfile_path, 'w+') as f:
            for ip in ips:
                #f.write(f'{ip} slots=4') # Cloud track
                f.write(f'{ip} slots=16') # Parallel track
                f.write('\n')
            return hostfile_path

    def get_command(self, input_json):
        problem_path = input_json.get("problem_path")
        worker_node_ips = input_json.get("worker_node_ips", [])
        
        combined_hostfile = self.create_hostfile(worker_node_ips, self.request_directory)

        run_list = ["/competition/run_mallob.sh"]
        run_list.append(combined_hostfile)
        run_list.append(problem_path)

        return run_list


class MallobParser:
    @staticmethod
    def get_result(output_file):
        """
        TODO: Participants should replace this with something more robust for their own solver!
        """
        with open(output_file) as f:
            raw_logs = f.read()
            if "s UNSATISFIABLE" in raw_logs:
                return "UNSATISFIABLE"
            elif "s SATISFIABLE" in raw_logs:
                return "SATISFIABLE"
            elif "result SAT" in raw_logs:
                return "SATISFIABLE"
            elif "result UNSAT" in raw_logs:
                return "UNSATISFIABLE"
            elif "[ERROR]" in raw_logs:
                return "ERROR"
            else:
                return "UNKNOWN"

if __name__ == "__main__":
    
    request_directory = sys.argv[1]
    runner = Runner(request_directory)
    runner.logger.info("Hello from /competition/solver")
    
    input_json = runner.get_input_json()
    cmd = runner.get_command(input_json)
    
    runner.logger.info("Running solver ...")
    
    output = runner.run(cmd)
    result = MallobParser.get_result(output["stdout"])
    logging.info(f"RESULT: {result}")
    solver_output = {
        "return_code": output["return_code"],
        "result": result,
        "artifacts": {
            "stdout_path": output["stdout"],
            "stderr_path": output["stderr"]
        }
    }
    
    with open(os.path.join(request_directory, "solver_out.json"), "w+") as f:
        f.write(json.dumps(solver_output))
